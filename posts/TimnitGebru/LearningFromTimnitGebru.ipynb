{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Learning From Dr. Timnit Gebru\n",
    "author: Mead Gyawu\n",
    "date: '2023-04-19'\n",
    "description: \"Learning From Dr. Timnit Gebru\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About Timnit Gebru\n",
    "\n",
    "Dr. Timnit Gebru, born an raised in Addis Ababa, Ethiopia, is a computer scientist with a PHD in computer Vision who dedicated her life to uncovering algorithmic bias against marginalized groups in artificial intelligence tools employed by major technology companies. Her passion for exposing bias was inspired by her own experience in school and with police. Having worked at major tech giants herself, Dr. Gebru understands the dangers that large language models could pose, which inspired her to write the paper \"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?\" However, she was then fired by Google after they saw what she had intened on publishing to be a threat. She now pursues her passion independently after she established Distributed Artificial Intelligence Research Institute (DAIR) and her work convinced the state of California to crack down on the racial biases present in major tech companies located there. Now, on Monday April 24th, Dr. Gebru has decided to hold a talk at middlebury about the use of artifical intelligence and how it intersects with the promotion of eugenics by some."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gebru's Talk Regarding Computer Vision\n",
    "\n",
    "During her talk, Dr. Gebru made emphasized the various issues and dangers present in the rollout and use of of computer vision. Initiall, facial recogniton technology released by major tech companies were extremely accurate when guessing the race and gender of White men, but were almost random in identifying Black women. This is the result of datasets that consistented mainly of or focused purely on male eurocentric features.\n",
    "\n",
    "She highlighted the fact that because bias and intentionally flawed computer vision technology is often used by police, either to search for those with warrants or to find and arrest protestors, often times people have and will continue to be arrested by the police wrongfully. Given the fact that Black and hispanic populations are already disproportionately targeted, this will essentially become another tool in their oppression.\n",
    "\n",
    "This goes te same for tools made to identify those who are transgendered or gay. Facial recognition technology that would classify those as gay or transgendered would be dangerous tools in the hands of those who seek to persecute them. Essentially, computer vision has already become a tool that furthers the discrimination that marginalized communities face."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question for Dr. Gebru\n",
    "\n",
    "##### The knowledge and impacts of highly flawed facial recognition tools is public knowledge. However, companies like Google and Amazon refuse to publically acknowledge the harm that their algorithims can cause. What incentive or reason would these businesses have for releasing largely flawed tools?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "\n",
    "In both the class discussion as well as her talk, Dr. Gebru touched on the dangers and greed that defined the pursuit and investment in AI and AGI by major tech companies. The dangers that AI technologies pose to marginalized groups, the exploitation of people both in the US and abroad, and the hoarding of resources from smaller businesses pursuing specialized AI technology are things that I resonate with. These are all things we see businesses do in other industries so their presence in AI research and products is not a surprise. The thing that did surprise me, however, were the ties to eugenics that Dr. Gebru explained. When I typically here of eugenics, I mostly thought of what Dr. Gebru defined as first wave eugenics, which is the desire to improve human stock by getting rid of undesirable traits or people. This idea of eugenics had largely classist, racist, ethnically prejudiced, and ableist overtones. However, I never thought of the potential intersection of eugenics and AI. While this push for AGI could be seen as having these same overtones, eugenics, to me at the very least, just seemed like a way for wealthy and predominantly White elites to use a false understanding of biology to ensure their growth and power while ridding themselves of having to associate with those that they see below them. That's not to say that those same elites would not use AGI to strengthen their control and hegemony, but more so that it would be through various tools used to oppress other groups that they see as undesirable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
